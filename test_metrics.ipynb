{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a90f429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcce139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------\n",
    "# Configuration Parameters\n",
    "# --------------------------------\n",
    "SEQUENCE_LENGTH = 16       # Number of frames per video clip\n",
    "IMG_SIZE = (224, 224)      # Frame dimensions (compatible with MobileNetV2)\n",
    "BATCH_SIZE = 8             # Batch size for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccde47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------\n",
    "# 1. Load File Paths from Folders\n",
    "# --------------------------------\n",
    "# Directories for Accident and NoAccident videos\n",
    "accident_dir = \"ProcessedDataset/Accident\"\n",
    "noaccident_dir = \"ProcessedDataset/NoAccident\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b7cc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of video files (adjust file extensions as needed)\n",
    "accident_files = [os.path.join(accident_dir, f) for f in os.listdir(accident_dir)\n",
    "                  if f.lower().endswith(('.mp4', '.avi', '.mov'))]\n",
    "noaccident_files = [os.path.join(noaccident_dir, f) for f in os.listdir(noaccident_dir)\n",
    "                    if f.lower().endswith(('.mp4', '.avi', '.mov'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179d37f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine file paths and labels (Accident = 1, NoAccident = 0)\n",
    "all_files = accident_files + noaccident_files\n",
    "all_labels = [1] * len(accident_files) + [0] * len(noaccident_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad5c7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total Accident videos:\", len(accident_files))\n",
    "print(\"Total NoAccident videos:\", len(noaccident_files))\n",
    "print(\"Total videos:\", len(all_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3074b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------\n",
    "# 2. Split into Train+Validation and Test Sets\n",
    "# --------------------------------\n",
    "# Since you don't have a separate test folder, we use a 20% test split.\n",
    "_, test_files, _, test_labels = train_test_split(\n",
    "    all_files, all_labels, test_size=0.2, random_state=42, stratify=all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a721d59e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "print(\"\\nTotal Test Videos:\", len(test_files))\n",
    "print(\"Test Accident videos:\", sum(1 for l in test_labels if l == 1))\n",
    "print(\"Test NoAccident videos:\", sum(1 for l in test_labels if l == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209aad53",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# --------------------------------\n",
    "# 3. Define Helper Function to Extract Frames\n",
    "# --------------------------------\n",
    "def extract_frames(video_path, num_frames=SEQUENCE_LENGTH, img_size=IMG_SIZE):\n",
    "    \"\"\"\n",
    "    Extracts 'num_frames' evenly spaced frames from the video at 'video_path'.\n",
    "    Resizes frames to 'img_size', converts to RGB, and normalizes pixel values.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Calculate indices: if video has fewer frames, duplicate the last frame as needed\n",
    "    if total_frames < num_frames:\n",
    "        indices = list(range(total_frames)) + [total_frames - 1] * (num_frames - total_frames)\n",
    "    else:\n",
    "        indices = np.linspace(0, total_frames - 1, num_frames, dtype=int)\n",
    "    \n",
    "    frame_id = 0\n",
    "    ret = True\n",
    "    while ret:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if frame_id in indices:\n",
    "            frame = cv2.resize(frame, img_size)\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frames.append(frame)\n",
    "        frame_id += 1\n",
    "    cap.release()\n",
    "    \n",
    "    # Ensure we have the required number of frames\n",
    "    while len(frames) < num_frames:\n",
    "        frames.append(frames[-1])\n",
    "    \n",
    "    frames = np.array(frames, dtype=\"float32\") / 255.0\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65edc5d6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# --------------------------------\n",
    "# 4. Define Test Data Generator\n",
    "# --------------------------------\n",
    "class VideoDataGenerator(Sequence):\n",
    "    \"\"\"\n",
    "    Keras Sequence generator that yields batches of video clips and labels.\n",
    "    No augmentation is applied in the test generator.\n",
    "    \"\"\"\n",
    "    def __init__(self, file_paths, labels, batch_size=BATCH_SIZE, sequence_length=SEQUENCE_LENGTH, shuffle=False):\n",
    "        self.file_paths = list(file_paths)\n",
    "        self.labels = list(labels)\n",
    "        self.batch_size = batch_size\n",
    "        self.sequence_length = sequence_length\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.file_paths) / self.batch_size)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_paths = self.file_paths[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_labels = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_X = []\n",
    "        for file_path in batch_paths:\n",
    "            frames = extract_frames(file_path, num_frames=self.sequence_length, img_size=IMG_SIZE)\n",
    "            batch_X.append(frames)\n",
    "        batch_X = np.array(batch_X)  # Shape: (batch_size, sequence_length, height, width, channels)\n",
    "        batch_y = np.array(batch_labels)\n",
    "        return batch_X, batch_y\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            combined = list(zip(self.file_paths, self.labels))\n",
    "            np.random.shuffle(combined)\n",
    "            self.file_paths, self.labels = zip(*combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112b60f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the test data generator\n",
    "test_gen = VideoDataGenerator(test_files, test_labels, batch_size=BATCH_SIZE, sequence_length=SEQUENCE_LENGTH, shuffle=False)\n",
    "print(\"Number of test batches:\", len(test_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10eab11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------\n",
    "# 5. Load the Trained Model and Compute Metrics\n",
    "# --------------------------------\n",
    "# Load your saved model (update the filename if necessary)\n",
    "model = load_model(\"final_accident_detection_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707cf6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect true labels and predicted labels from the test generator\n",
    "y_true = []\n",
    "y_pred = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b19f06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test_gen)):\n",
    "    batch_X, batch_y = test_gen[i]\n",
    "    preds = model.predict(batch_X)\n",
    "    # Convert predicted probabilities to binary predictions using threshold 0.5\n",
    "    preds_binary = (preds > 0.5).astype(int).flatten()\n",
    "    y_true.extend(batch_y)\n",
    "    y_pred.extend(preds_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276d1b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fc14fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------\n",
    "# 6. Log Additional Metrics\n",
    "# --------------------------------\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=[\"NoAccident\", \"Accident\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87479feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e43551",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision:\", precision_score(y_true, y_pred))\n",
    "print(\"Recall:\", recall_score(y_true, y_pred))\n",
    "print(\"F1-Score:\", f1_score(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
