{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5493c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652773cb",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Configuration Parameters\n",
    "# -------------------------------\n",
    "SEQUENCE_LENGTH = 16       # Number of frames to extract\n",
    "IMG_SIZE = (224, 224)      # Image dimensions (must match training)\n",
    "VIDEO_PATH = r\"ProcessedDataset\\NoAccident\\negative_samples_1112.mp4\"  # Replace with your video file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4781166c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Helper Function: Extract Frames\n",
    "# -------------------------------\n",
    "def extract_frames(video_path, num_frames=SEQUENCE_LENGTH, img_size=IMG_SIZE):\n",
    "    \"\"\"\n",
    "    Extracts 'num_frames' evenly spaced frames from the video at 'video_path'.\n",
    "    Each frame is resized to 'img_size', converted to RGB, and normalized.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Determine indices for evenly spaced frames\n",
    "    if total_frames < num_frames:\n",
    "        indices = list(range(total_frames)) + [total_frames - 1] * (num_frames - total_frames)\n",
    "    else:\n",
    "        indices = np.linspace(0, total_frames - 1, num_frames, dtype=int)\n",
    "    \n",
    "    frame_id = 0\n",
    "    ret = True\n",
    "    while ret:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if frame_id in indices:\n",
    "            frame = cv2.resize(frame, img_size)\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frames.append(frame)\n",
    "        frame_id += 1\n",
    "    cap.release()\n",
    "    \n",
    "    # Ensure we have exactly num_frames frames\n",
    "    while len(frames) < num_frames:\n",
    "        frames.append(frames[-1])\n",
    "    \n",
    "    frames = np.array(frames, dtype=\"float32\") / 255.0\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32acc032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Load the Pre-Trained Model\n",
    "# -------------------------------\n",
    "# Update the model path if needed.\n",
    "model = load_model(\"best_accident_detection_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7e2f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Prepare Video Input for Prediction\n",
    "# -------------------------------\n",
    "frames = extract_frames(VIDEO_PATH)\n",
    "# The model expects a batch dimension: (batch_size, SEQUENCE_LENGTH, height, width, channels)\n",
    "video_input = np.expand_dims(frames, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c029cfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Make a Prediction\n",
    "# -------------------------------\n",
    "prediction = model.predict(video_input)\n",
    "print(\"Prediction (probability):\", prediction[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13176885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a threshold of 0.5 for binary classification\n",
    "if prediction[0][0] > 0.5:\n",
    "    print(\"Accident detected.\")\n",
    "else:\n",
    "    print(\"No accident detected.\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
